{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Step 1 : importing Essential Libraries\n","\n","\n","These libraries collectively provide functionality for data preparation, model building, training, evaluation, and visualization for a deep learning task."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-08-17T09:40:21.702115Z","iopub.status.busy":"2023-08-17T09:40:21.701643Z","iopub.status.idle":"2023-08-17T09:40:41.946011Z","shell.execute_reply":"2023-08-17T09:40:41.945052Z","shell.execute_reply.started":"2023-08-17T09:40:21.702082Z"},"trusted":true},"outputs":[],"source":["import os\n","max_images = 5\n","input_directory = '/kaggle/input'\n","count = 0\n","for dirname, _, filenames in os.walk(input_directory):\n","    for filename in filenames:\n","        if count < max_images and filename.endswith(('.jpg', '.png', '.jpeg')):\n","            print(os.path.join(dirname, filename))\n","            count += 1"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-08-17T09:40:41.948985Z","iopub.status.busy":"2023-08-17T09:40:41.948219Z","iopub.status.idle":"2023-08-17T09:40:41.963590Z","shell.execute_reply":"2023-08-17T09:40:41.961756Z","shell.execute_reply.started":"2023-08-17T09:40:41.948949Z"},"trusted":true},"outputs":[],"source":["import matplotlib.pyplot as plt\n","import numpy as np\n","import pandas as pd\n","import os\n","from glob import glob\n","import seaborn as sns\n","from PIL import Image\n","np.random.seed(123)\n","from sklearn.preprocessing import label_binarize\n","from sklearn.metrics import confusion_matrix\n","import itertools\n","import tensorflow as tf\n","from tensorflow.keras.layers import BatchNormalization\n","from tensorflow.keras.utils import to_categorical\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.applications import EfficientNetB0\n","from tensorflow.keras.layers import GlobalAveragePooling2D, Dense\n","from tensorflow.keras.models import Model\n","\n","import keras\n","from tensorflow.keras.utils import to_categorical\n","from keras.models import Sequential\n","from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D\n","\n","from tensorflow.keras.layers import BatchNormalization\n","from tensorflow.keras.utils import to_categorical\n","from tensorflow.keras.optimizers import Adam\n","from keras.optimizers import Adam\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from keras.callbacks import ReduceLROnPlateau\n","from sklearn.model_selection import train_test_split"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-08-17T09:40:41.966062Z","iopub.status.busy":"2023-08-17T09:40:41.965350Z","iopub.status.idle":"2023-08-17T09:40:41.978303Z","shell.execute_reply":"2023-08-17T09:40:41.977043Z","shell.execute_reply.started":"2023-08-17T09:40:41.966025Z"},"trusted":true},"outputs":[],"source":["def plot_model_history(model_history):\n","    fig, axs = plt.subplots(1,2,figsize=(15,5))\n","    axs[0].plot(range(1,len(model_history.history['acc'])+1),model_history.history['acc'])\n","    axs[0].plot(range(1,len(model_history.history['val_acc'])+1),model_history.history['val_acc'])\n","    axs[0].set_title('Model Accuracy')\n","    axs[0].set_ylabel('Accuracy')\n","    axs[0].set_xlabel('Epoch')\n","    axs[0].set_xticks(np.arange(1,len(model_history.history['acc'])+1),len(model_history.history['acc'])/10)\n","    axs[0].legend(['train', 'val'], loc='best')\n","    axs[1].plot(range(1,len(model_history.history['loss'])+1),model_history.history['loss'])\n","    axs[1].plot(range(1,len(model_history.history['val_loss'])+1),model_history.history['val_loss'])\n","    axs[1].set_title('Model Loss')\n","    axs[1].set_ylabel('Loss')\n","    axs[1].set_xlabel('Epoch')\n","    axs[1].set_xticks(np.arange(1,len(model_history.history['loss'])+1),len(model_history.history['loss'])/10)\n","    axs[1].legend(['train', 'val'], loc='best')\n","    plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["# Step 2 : Making Dictionary of images and labels\n","In this step I have made the image path dictionary by joining the folder path from base directory base_skin_dir and merge the images in jpg format from both the folders HAM10000_images_part1.zip and HAM10000_images_part2.zip"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-08-17T09:40:41.981245Z","iopub.status.busy":"2023-08-17T09:40:41.980817Z","iopub.status.idle":"2023-08-17T09:40:42.129339Z","shell.execute_reply":"2023-08-17T09:40:42.128293Z","shell.execute_reply.started":"2023-08-17T09:40:41.981211Z"},"trusted":true},"outputs":[],"source":["base_skin_dir = os.path.join('..', '/Users/deekshithkandregula/Downloads/Skin cancer')\n","\n","imageid_path_dict = {os.path.splitext(os.path.basename(x))[0]: x\n","                     for x in glob(os.path.join(base_skin_dir, '*', '*.jpg'))}\n","\n","lesion_type_dict = {\n","    'nv': 'Melanocytic nevi',\n","    'mel': 'Melanoma',\n","    'bkl': 'Benign keratosis-like lesions ',\n","    'bcc': 'Basal cell carcinoma',\n","    'akiec': 'Actinic keratoses',\n","    'vasc': 'Vascular lesions',\n","    'df': 'Dermatofibroma'\n","}"]},{"cell_type":"markdown","metadata":{},"source":["# Step 3 : Reading & Processing data\n","In this step we have read the csv by joining the path of image folder which is the base folder where all the images are placed named base_skin_dir. After that we made some new columns which is easily understood for later reference such as we have made column path which contains the image_id, cell_type which contains the short name of lesion type and at last we have made the categorical column cell_type_idx in which we have categorize the lesion type in to codes from 0 to 6"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-08-17T09:40:42.300266Z","iopub.status.busy":"2023-08-17T09:40:42.299903Z","iopub.status.idle":"2023-08-17T09:40:42.333749Z","shell.execute_reply":"2023-08-17T09:40:42.332698Z","shell.execute_reply.started":"2023-08-17T09:40:42.300238Z"},"trusted":true},"outputs":[],"source":["skin_df = pd.read_csv(os.path.join(base_skin_dir, 'HAM10000_metadata.csv'))\n","\n","skin_df['path'] = skin_df['image_id'].map(imageid_path_dict.get)\n","skin_df['cell_type'] = skin_df['dx'].map(lesion_type_dict.get) \n","skin_df['cell_type_idx'] = pd.Categorical(skin_df['cell_type']).codes"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-08-16T14:18:57.681748Z","iopub.status.busy":"2023-08-16T14:18:57.681307Z","iopub.status.idle":"2023-08-16T14:18:57.705132Z","shell.execute_reply":"2023-08-16T14:18:57.704089Z","shell.execute_reply.started":"2023-08-16T14:18:57.681710Z"},"trusted":true},"outputs":[],"source":["skin_df.head()"]},{"cell_type":"markdown","metadata":{},"source":["# Step 4 : Data Cleaning\n","In this step we check for Missing values and datatype of each field"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-08-17T09:40:44.331868Z","iopub.status.busy":"2023-08-17T09:40:44.331514Z","iopub.status.idle":"2023-08-17T09:40:44.367617Z","shell.execute_reply":"2023-08-17T09:40:44.366748Z","shell.execute_reply.started":"2023-08-17T09:40:44.331839Z"},"trusted":true},"outputs":[],"source":["skin_df.isnull().sum()"]},{"cell_type":"markdown","metadata":{},"source":["As it is evident from the above that only age has null values which is 57 so we will fill the null values by their mean."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-08-17T09:40:46.830203Z","iopub.status.busy":"2023-08-17T09:40:46.829828Z","iopub.status.idle":"2023-08-17T09:40:46.838976Z","shell.execute_reply":"2023-08-17T09:40:46.837955Z","shell.execute_reply.started":"2023-08-17T09:40:46.830175Z"},"trusted":true},"outputs":[],"source":["skin_df['age'].fillna((skin_df['age'].mean()), inplace=True)"]},{"cell_type":"markdown","metadata":{},"source":["Now, lets check the presence of null values again"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-08-16T14:19:06.500841Z","iopub.status.busy":"2023-08-16T14:19:06.500466Z","iopub.status.idle":"2023-08-16T14:19:06.534788Z","shell.execute_reply":"2023-08-16T14:19:06.533683Z","shell.execute_reply.started":"2023-08-16T14:19:06.500811Z"},"trusted":true},"outputs":[],"source":["skin_df.isnull().sum()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-08-17T09:40:51.674849Z","iopub.status.busy":"2023-08-17T09:40:51.674502Z","iopub.status.idle":"2023-08-17T09:40:51.681385Z","shell.execute_reply":"2023-08-17T09:40:51.679924Z","shell.execute_reply.started":"2023-08-17T09:40:51.674819Z"},"trusted":true},"outputs":[],"source":["print(skin_df.dtypes)"]},{"cell_type":"markdown","metadata":{},"source":["# Step 5 : EDA\n","In this we will explore different features of the dataset , their distrubtions and actual counts\n","\n","Plot to see distribution of 7 different classes of cell type"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-08-17T09:40:57.257300Z","iopub.status.busy":"2023-08-17T09:40:57.256357Z","iopub.status.idle":"2023-08-17T09:40:57.605769Z","shell.execute_reply":"2023-08-17T09:40:57.604839Z","shell.execute_reply.started":"2023-08-17T09:40:57.257256Z"},"trusted":true},"outputs":[],"source":["fig, ax1 = plt.subplots(1, 1, figsize= (10, 5))\n","skin_df['cell_type'].value_counts().plot(kind='bar', ax=ax1)"]},{"cell_type":"markdown","metadata":{},"source":["Its seems from the above plot that in this dataset cell type Melanecytic nevi has very large number of instances in comparison to other cell types\n","\n","Plotting of Technical Validation field (ground truth) which is dx_type to see the distribution of its 4 categories which are listed below :\n","1. Histopathology(Histo): Histopathologic diagnoses of excised lesions have been performed by specialized dermatopathologists.\n","2. Confocal: Reflectance confocal microscopy is an in-vivo imaging technique with a resolution at near-cellular level , and some facial benign with a grey-world assumption of all training-set images in Lab-color space before and after manual histogram changes.\n","3. Follow-up: If nevi monitored by digital dermatoscopy did not show any changes during 3 follow-up visits or 1.5 years biologists accepted this as evidence of biologic benignity. Only nevi, but no other benign diagnoses were labeled with this type of ground-truth because dermatologists usually do not monitor dermatofibromas, seborrheic keratoses, or vascular lesions.\n","4. Consensus: For typical benign cases without histopathology or followup biologists provide an expert-consensus rating of authors PT and HK. They applied the consensus label only if both authors independently gave the same unequivocal benign diagnosis. Lesions with this type of groundtruth were usually photographed for educational reasons and did not need further follow-up or biopsy for confirmation."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-08-17T09:41:01.443707Z","iopub.status.busy":"2023-08-17T09:41:01.443351Z","iopub.status.idle":"2023-08-17T09:41:01.684821Z","shell.execute_reply":"2023-08-17T09:41:01.683817Z","shell.execute_reply.started":"2023-08-17T09:41:01.443679Z"},"trusted":true},"outputs":[],"source":["skin_df['dx_type'].value_counts().plot(kind='bar')"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-08-17T09:41:04.927893Z","iopub.status.busy":"2023-08-17T09:41:04.927526Z","iopub.status.idle":"2023-08-17T09:41:05.246498Z","shell.execute_reply":"2023-08-17T09:41:05.245561Z","shell.execute_reply.started":"2023-08-17T09:41:04.927849Z"},"trusted":true},"outputs":[],"source":["skin_df['localization'].value_counts().plot(kind='bar')"]},{"cell_type":"markdown","metadata":{},"source":["It seems back , lower extremity,trunk and upper extremity are heavily compromised regions of skin cancer\n","\n","Now, check the distribution of Age"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-08-16T14:19:24.694706Z","iopub.status.busy":"2023-08-16T14:19:24.694302Z","iopub.status.idle":"2023-08-16T14:19:25.033050Z","shell.execute_reply":"2023-08-16T14:19:25.031952Z","shell.execute_reply.started":"2023-08-16T14:19:24.694676Z"},"trusted":true},"outputs":[],"source":["skin_df['age'].hist(bins=40)"]},{"cell_type":"markdown","metadata":{},"source":["It seems that there are larger instances of patients having age from 30 to 60\n","\n","Lets see the distribution of males and females"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-08-17T09:41:07.856411Z","iopub.status.busy":"2023-08-17T09:41:07.855366Z","iopub.status.idle":"2023-08-17T09:41:08.088734Z","shell.execute_reply":"2023-08-17T09:41:08.087806Z","shell.execute_reply.started":"2023-08-17T09:41:07.856371Z"},"trusted":true},"outputs":[],"source":["skin_df['sex'].value_counts().plot(kind='bar')"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-08-16T14:19:32.449115Z","iopub.status.busy":"2023-08-16T14:19:32.448641Z","iopub.status.idle":"2023-08-16T14:19:32.886149Z","shell.execute_reply":"2023-08-16T14:19:32.885091Z","shell.execute_reply.started":"2023-08-16T14:19:32.449077Z"},"trusted":true},"outputs":[],"source":["sns.scatterplot(x='age', y='cell_type_idx', data=skin_df)\n"]},{"cell_type":"markdown","metadata":{},"source":["It seems that skin cancer types 0,1, 3 and 5 which are Melanocytic nevi,dermatofibroma,Basal cell carcinoma and Vascular lesions are not much prevalant below the age of 20 years\n","\n","Sexwise distribution of skin cancer type"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-08-17T09:41:14.194249Z","iopub.status.busy":"2023-08-17T09:41:14.193707Z","iopub.status.idle":"2023-08-17T09:41:14.634254Z","shell.execute_reply":"2023-08-17T09:41:14.632950Z","shell.execute_reply.started":"2023-08-17T09:41:14.194205Z"},"trusted":true},"outputs":[],"source":["sns.catplot(x='sex', y='cell_type_idx', data=skin_df)\n"]},{"cell_type":"markdown","metadata":{},"source":["# Step 6: Loading and resizing of images\n","In this step images will be loaded into the column named image from the image path from the image folder. We also resize the images as the original dimension of images are 450 x 600 x3 which TensorFlow can't handle, so that's why we resize it into 100 x 75. As this step resize all the 10015 images dimensions into 100x 75 so be patient it will take some time."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-08-17T09:42:08.479648Z","iopub.status.busy":"2023-08-17T09:42:08.479288Z","iopub.status.idle":"2023-08-17T09:44:46.059290Z","shell.execute_reply":"2023-08-17T09:44:46.058284Z","shell.execute_reply.started":"2023-08-17T09:42:08.479619Z"},"trusted":true},"outputs":[],"source":["skin_df['image'] = skin_df['path'].map(lambda x: np.asarray(Image.open(x).resize((100,75))))"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-08-17T09:44:52.547095Z","iopub.status.busy":"2023-08-17T09:44:52.546709Z","iopub.status.idle":"2023-08-17T09:45:07.393845Z","shell.execute_reply":"2023-08-17T09:45:07.392821Z","shell.execute_reply.started":"2023-08-17T09:44:52.547063Z"},"trusted":true},"outputs":[],"source":["skin_df.head()"]},{"cell_type":"markdown","metadata":{},"source":["As we can see image column has been added in its color format code\n","\n","Most interesting part its always better to see sample of images Below we will show images of each cancer type"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-08-17T09:45:16.278428Z","iopub.status.busy":"2023-08-17T09:45:16.277773Z","iopub.status.idle":"2023-08-17T09:45:22.636818Z","shell.execute_reply":"2023-08-17T09:45:22.635948Z","shell.execute_reply.started":"2023-08-17T09:45:16.278395Z"},"trusted":true},"outputs":[],"source":["n_samples = 5\n","fig, m_axs = plt.subplots(7, n_samples, figsize = (4*n_samples, 3*7))\n","for n_axs, (type_name, type_rows) in zip(m_axs, \n","                                         skin_df.sort_values(['cell_type']).groupby('cell_type')):\n","    n_axs[0].set_title(type_name)\n","    for c_ax, (_, c_row) in zip(n_axs, type_rows.sample(n_samples, random_state=1234).iterrows()):\n","        c_ax.imshow(c_row['image'])\n","        c_ax.axis('off')\n","fig.savefig('category_samples.png', dpi=300)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-08-17T09:48:11.148055Z","iopub.status.busy":"2023-08-17T09:48:11.147659Z","iopub.status.idle":"2023-08-17T09:48:11.163961Z","shell.execute_reply":"2023-08-17T09:48:11.162944Z","shell.execute_reply.started":"2023-08-17T09:48:11.148025Z"},"trusted":true},"outputs":[],"source":["skin_df['image'].map(lambda x: x.shape).value_counts()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-08-17T09:48:15.011455Z","iopub.status.busy":"2023-08-17T09:48:15.010773Z","iopub.status.idle":"2023-08-17T09:48:15.019337Z","shell.execute_reply":"2023-08-17T09:48:15.018163Z","shell.execute_reply.started":"2023-08-17T09:48:15.011420Z"},"trusted":true},"outputs":[],"source":["features=skin_df.drop(columns=['cell_type_idx'],axis=1)\n","target=skin_df['cell_type_idx']"]},{"cell_type":"markdown","metadata":{},"source":["# Step 7 : Train Test Split\n","In this step we have splitted the dataset into training and testing set of 80:20 ratio"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-08-17T09:48:29.350317Z","iopub.status.busy":"2023-08-17T09:48:29.349958Z","iopub.status.idle":"2023-08-17T09:48:29.363110Z","shell.execute_reply":"2023-08-17T09:48:29.361926Z","shell.execute_reply.started":"2023-08-17T09:48:29.350286Z"},"trusted":true},"outputs":[],"source":["x_train_o, x_test_o, y_train_o, y_test_o = train_test_split(features, target, test_size=0.20,random_state=1234)"]},{"cell_type":"markdown","metadata":{},"source":["# Step 8 : Normalization\n","I choosed to normalize the x_train, x_test by substracting from theor mean values and then dividing by thier standard deviation."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-08-17T09:48:30.581630Z","iopub.status.busy":"2023-08-17T09:48:30.581243Z","iopub.status.idle":"2023-08-17T09:48:32.534631Z","shell.execute_reply":"2023-08-17T09:48:32.533557Z","shell.execute_reply.started":"2023-08-17T09:48:30.581601Z"},"trusted":true},"outputs":[],"source":["x_train = np.asarray(x_train_o['image'].tolist())\n","x_test = np.asarray(x_test_o['image'].tolist())\n","\n","x_train_mean = np.mean(x_train)\n","x_train_std = np.std(x_train)\n","\n","x_test_mean = np.mean(x_test)\n","x_test_std = np.std(x_test)\n","\n","x_train = (x_train - x_train_mean)/x_train_std\n","x_test = (x_test - x_test_mean)/x_test_std"]},{"cell_type":"markdown","metadata":{},"source":["# Step 9 : Label Encoding\n","Labels are 7 different classes of skin cancer types from 0 to 6. We need to encode these lables to one hot vectors"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-08-17T09:48:41.006361Z","iopub.status.busy":"2023-08-17T09:48:41.005615Z","iopub.status.idle":"2023-08-17T09:48:41.012418Z","shell.execute_reply":"2023-08-17T09:48:41.011174Z","shell.execute_reply.started":"2023-08-17T09:48:41.006322Z"},"trusted":true},"outputs":[],"source":["y_train = to_categorical(y_train_o, num_classes = 7)\n","y_test = to_categorical(y_test_o, num_classes = 7)"]},{"cell_type":"markdown","metadata":{},"source":["# Step 10 : Splitting training and validation split\n","I choosed to split the train set in two parts : a small fraction (10%) became the validation set which the model is evaluated and the rest (90%) is used to train the model."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-08-17T09:48:43.752970Z","iopub.status.busy":"2023-08-17T09:48:43.752589Z","iopub.status.idle":"2023-08-17T09:48:44.176012Z","shell.execute_reply":"2023-08-17T09:48:44.174940Z","shell.execute_reply.started":"2023-08-17T09:48:43.752939Z"},"trusted":true},"outputs":[],"source":["x_train, x_validate, y_train, y_validate = train_test_split(x_train, y_train, test_size = 0.1, random_state = 2)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-08-17T09:48:51.991489Z","iopub.status.busy":"2023-08-17T09:48:51.991131Z","iopub.status.idle":"2023-08-17T09:48:51.997718Z","shell.execute_reply":"2023-08-17T09:48:51.996407Z","shell.execute_reply.started":"2023-08-17T09:48:51.991459Z"},"trusted":true},"outputs":[],"source":["x_train = x_train.reshape(x_train.shape[0], *(75, 100, 3))\n","x_test = x_test.reshape(x_test.shape[0], *(75, 100, 3))\n","x_validate = x_validate.reshape(x_validate.shape[0], *(75, 100, 3))"]},{"cell_type":"markdown","metadata":{},"source":["# #Step 11: Model Building"]},{"cell_type":"markdown","metadata":{},"source":["CNN\n","I used the Keras Sequential API, where you have just to add one layer at a time, starting from the input.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-08-14T18:47:01.947930Z","iopub.status.busy":"2023-08-14T18:47:01.947458Z","iopub.status.idle":"2023-08-14T18:47:06.951043Z","shell.execute_reply":"2023-08-14T18:47:06.950201Z","shell.execute_reply.started":"2023-08-14T18:47:01.947893Z"},"trusted":true},"outputs":[],"source":["# Set the CNN model \n","# my CNN architechture is In -> [[Conv2D->relu]*2 -> MaxPool2D -> Dropout]*2 -> Flatten -> Dense -> Dropout -> Out\n","input_shape = (75, 100, 3)\n","num_classes = 7\n","\n","model = Sequential()\n","model.add(Conv2D(32, kernel_size=(3, 3),activation='relu',padding = 'Same',input_shape=input_shape))\n","model.add(Conv2D(32,kernel_size=(3, 3), activation='relu',padding = 'Same',))\n","model.add(MaxPool2D(pool_size = (2, 2)))\n","model.add(Dropout(0.25))\n","\n","model.add(Conv2D(64, (3, 3), activation='relu',padding = 'Same'))\n","model.add(Conv2D(64, (3, 3), activation='relu',padding = 'Same'))\n","model.add(MaxPool2D(pool_size=(2, 2)))\n","model.add(Dropout(0.40))\n","\n","model.add(Flatten())\n","model.add(Dense(128, activation='relu'))\n","model.add(Dropout(0.5))\n","model.add(Dense(num_classes, activation='softmax'))\n","model.summary()"]},{"cell_type":"markdown","metadata":{},"source":["# Step 12: Setting Optimizer and Annealer\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-08-14T18:47:25.142435Z","iopub.status.busy":"2023-08-14T18:47:25.142076Z","iopub.status.idle":"2023-08-14T18:47:25.152639Z","shell.execute_reply":"2023-08-14T18:47:25.151336Z","shell.execute_reply.started":"2023-08-14T18:47:25.142406Z"},"trusted":true},"outputs":[],"source":["optimizer = Adam(\n","    learning_rate=0.001,\n","    beta_1=0.9,\n","    beta_2=0.999,\n","    epsilon=None,\n","    decay=0.0,\n","    amsgrad=False\n",")\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-08-14T18:47:27.456497Z","iopub.status.busy":"2023-08-14T18:47:27.456129Z","iopub.status.idle":"2023-08-14T18:47:27.726861Z","shell.execute_reply":"2023-08-14T18:47:27.725709Z","shell.execute_reply.started":"2023-08-14T18:47:27.456465Z"},"trusted":true},"outputs":[],"source":["model.compile(optimizer = optimizer , loss = \"categorical_crossentropy\", metrics=[\"accuracy\"])"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-08-14T18:47:38.508203Z","iopub.status.busy":"2023-08-14T18:47:38.507814Z","iopub.status.idle":"2023-08-14T18:47:38.514140Z","shell.execute_reply":"2023-08-14T18:47:38.512874Z","shell.execute_reply.started":"2023-08-14T18:47:38.508167Z"},"trusted":true},"outputs":[],"source":["learning_rate_reduction = ReduceLROnPlateau(monitor='val_acc', \n","                                            patience=3, \n","                                            verbose=1, \n","                                            factor=0.5, \n","                                            min_lr=0.00001)"]},{"cell_type":"markdown","metadata":{},"source":["# Data Augmentation\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-08-14T18:47:45.827131Z","iopub.status.busy":"2023-08-14T18:47:45.826395Z","iopub.status.idle":"2023-08-14T18:47:46.308866Z","shell.execute_reply":"2023-08-14T18:47:46.307808Z","shell.execute_reply.started":"2023-08-14T18:47:45.827093Z"},"trusted":true},"outputs":[],"source":["datagen = ImageDataGenerator(\n","        featurewise_center=False, \n","        samplewise_center=False,  \n","        featurewise_std_normalization=False,  \n","        samplewise_std_normalization=False, \n","        zca_whitening=False, \n","        rotation_range=10,  \n","        zoom_range = 0.1,\n","        width_shift_range=0.1, \n","        height_shift_range=0.1,  \n","        horizontal_flip=False, \n","        vertical_flip=False)  \n","\n","datagen.fit(x_train)"]},{"cell_type":"markdown","metadata":{},"source":["For the data augmentation, i choosed to : Randomly rotate some training images by 10 degrees Randomly Zoom by 10% some training images Randomly shift images horizontally by 10% of the width Randomly shift images vertically by 10% of the height Once our model is ready, we fit the training dataset ."]},{"cell_type":"markdown","metadata":{},"source":["# Step 13: Fitting the model\n","In this step finally I fit the model into x_train, y_train. In this step I have choosen batch size of 10 and 50 epochs as small as your batch size will be more efficiently your model will train and I have choosen 50 epochs to give the model sufficient epochs to train"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-08-14T18:47:48.930265Z","iopub.status.busy":"2023-08-14T18:47:48.929579Z","iopub.status.idle":"2023-08-14T19:04:02.589340Z","shell.execute_reply":"2023-08-14T19:04:02.587342Z","shell.execute_reply.started":"2023-08-14T18:47:48.930230Z"},"trusted":true},"outputs":[],"source":["epochs = 50\n","batch_size = 10\n","\n","def lr_schedule(epoch):\n","    lr = 0.001\n","    if epoch > 10:\n","        lr *= 0.5\n","    return lr\n","\n","model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n","\n","try:\n","    history = model.fit(\n","        datagen.flow(x_train, y_train, batch_size=batch_size),\n","        epochs=epochs,\n","        validation_data=(x_validate, y_validate),\n","        verbose=1,\n","        steps_per_epoch=x_train.shape[0] // batch_size,\n","        callbacks=[LearningRateScheduler(lr_schedule)]\n","    )\n","except Exception as e:\n","    print(f\"An error occurred during training: {e}\")\n","    raise\n"]},{"cell_type":"markdown","metadata":{},"source":["# Step 14: Model Evaluation¶\n","In this step we will check the testing accuracy and validation accuracy of our model,plot confusion matrix and also check the missclassified images count of each type"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-08-14T19:04:36.816252Z","iopub.status.busy":"2023-08-14T19:04:36.815534Z","iopub.status.idle":"2023-08-14T19:04:38.650520Z","shell.execute_reply":"2023-08-14T19:04:38.649435Z","shell.execute_reply.started":"2023-08-14T19:04:36.816204Z"},"trusted":true},"outputs":[],"source":["loss, accuracy = model.evaluate(x_test, y_test, verbose=1)\n","loss_v, accuracy_v = model.evaluate(x_validate, y_validate, verbose=1)\n","print(\"Validation: accuracy = %f  ;  loss_v = %f\" % (accuracy_v, loss_v))\n","print(\"Test: accuracy = %f  ;  loss = %f\" % (accuracy, loss))\n","model.save(\"model.h5\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-08-14T19:08:50.376713Z","iopub.status.busy":"2023-08-14T19:08:50.376307Z","iopub.status.idle":"2023-08-14T19:08:51.052647Z","shell.execute_reply":"2023-08-14T19:08:51.051627Z","shell.execute_reply.started":"2023-08-14T19:08:50.376676Z"},"trusted":true},"outputs":[],"source":["def plot_model_history(model_history):\n","    fig, axs = plt.subplots(1, 2, figsize=(15, 5))\n","    \n","    axs[0].plot(range(1, len(model_history.history['accuracy']) + 1), model_history.history['accuracy'], label='Training Accuracy')\n","    axs[0].plot(range(1, len(model_history.history['val_accuracy']) + 1), model_history.history['val_accuracy'], label='Validation Accuracy')\n","    axs[0].set_title('Model Accuracy')\n","    axs[0].set_xlabel('Epoch')\n","    axs[0].set_ylabel('Accuracy')\n","    axs[0].legend()\n","\n","    axs[1].plot(range(1, len(model_history.history['loss']) + 1), model_history.history['loss'], label='Training Loss')\n","    axs[1].plot(range(1, len(model_history.history['val_loss']) + 1), model_history.history['val_loss'], label='Validation Loss')\n","    axs[1].set_title('Model Loss')\n","    axs[1].set_xlabel('Epoch')\n","    axs[1].set_ylabel('Loss')\n","    axs[1].legend()\n","\n","    plt.tight_layout()\n","    plt.show()\n","\n","plot_model_history(history)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-08-14T19:12:24.627312Z","iopub.status.busy":"2023-08-14T19:12:24.626905Z","iopub.status.idle":"2023-08-14T19:12:25.712617Z","shell.execute_reply":"2023-08-14T19:12:25.711637Z","shell.execute_reply.started":"2023-08-14T19:12:24.627280Z"},"trusted":true},"outputs":[],"source":["def plot_confusion_matrix(cm, classes,\n","                          normalize=False,\n","                          title='Confusion matrix',\n","                          cmap=plt.cm.Blues):\n","    \"\"\"\n","    This function prints and plots the confusion matrix.\n","    Normalization can be applied by setting `normalize=True`.\n","    \"\"\"\n","    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n","    plt.title(title)\n","    plt.colorbar()\n","    tick_marks = np.arange(len(classes))\n","    plt.xticks(tick_marks, classes, rotation=45)\n","    plt.yticks(tick_marks, classes)\n","\n","    if normalize:\n","        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n","\n","    thresh = cm.max() / 2.\n","    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n","        plt.text(j, i, cm[i, j],\n","                 horizontalalignment=\"center\",\n","                 color=\"white\" if cm[i, j] > thresh else \"black\")\n","\n","    plt.tight_layout()\n","    plt.ylabel('True label')\n","    plt.xlabel('Predicted label')\n","\n","Y_pred = model.predict(x_validate)\n","Y_pred_classes = np.argmax(Y_pred,axis = 1) \n","Y_true = np.argmax(y_validate,axis = 1) \n","confusion_mtx = confusion_matrix(Y_true, Y_pred_classes)\n","\n","plot_confusion_matrix(confusion_mtx, classes = range(7)) "]},{"cell_type":"markdown","metadata":{},"source":["Now, lets which category has much incorrect predictions"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-08-14T19:13:24.181532Z","iopub.status.busy":"2023-08-14T19:13:24.181142Z","iopub.status.idle":"2023-08-14T19:13:24.472101Z","shell.execute_reply":"2023-08-14T19:13:24.471134Z","shell.execute_reply.started":"2023-08-14T19:13:24.181501Z"},"trusted":true},"outputs":[],"source":["label_frac_error = 1 - np.diag(confusion_mtx) / np.sum(confusion_mtx, axis=1)\n","plt.bar(np.arange(7),label_frac_error)\n","plt.xlabel('True Label')\n","plt.ylabel('Fraction classified incorrectly')"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.2"}},"nbformat":4,"nbformat_minor":4}
